#Use case description:
#1.create cluster
#2.cycle query status
#3.check computer node write and read
#4.check shard master and slave 
#5.backup the src cluster
#6.add shards
#7.expand cluster
#8.result : the cluster_general_job_log of meta status is done.

--http_connect(cluster_mgr_http1, cluster_mgr,50000)

--http
request_type: POST
header:Content-Type:application/json
body:{
        "version":"1.0",
        "job_id":"",
        "job_type":"create_cluster",
        "user_name":"kunlun_test",
        "timestamp":"202205131532",
        "paras":{
              "nick_name":"rbrcluster001",
              "ha_mode":"rbr",
              "shards":"1",
              "nodes":"3",
              "comps":"1",
              "max_storage_size":"20",
              "max_connections":"6",
              "cpu_cores":"8",
              "innodb_size":"1",
              "dbcfg":"1",
              "fullsync_level": "1",
              "storage_iplists": [
                   "${node_mgr.1}"
                          ],
              "computer_iplists": [
                   "${node_mgr.1}"
                           ]
  }           
}
EOF

--let $job_id = `http_reap(job_id)`
--sleep 20
--source kunlun-test/include/wait_http_request_finish.inc

#check shard master and slave
--kl_cluster_id(1)
--source kunlun-test/include/check_shard_state.inc

#check cn
--pg_connect(testrbr1,computer.1, abc, abc)
--source kunlun-test/include/check_cn_write_read.inc
create table student(id int primary key, info text, wt int);
insert into student(id,info,wt) values(1, 'record1', 1);
insert into student(id,info,wt) values(2, 'record2', 2);
--sleep 20

--connection cluster_mgr_http1
--http
request_type: POST
header:Content-Type:application/json
body:{
        "version":"1.0",
        "job_id":"",
        "job_type":"add_shards",
        "user_name":"kunlun_test",
        "timestamp":"202205131532",
        "paras":{
              "cluster_id":"${cluster_id}",
              "shards":"1",
              "nodes":"2",
              "storage_iplists":[
                         "${node_mgr.1}"
                ]
              }
}
EOF

--let $job_id = `http_reap(job_id)`
--sleep 20
--source kunlun-test/include/wait_http_request_finish.inc

--kl_cluster_id(1)
--source kunlun-test/include/check_shard_state.inc

--connection default
--let $dst_shard_id = `select distinct shard_id from shard_nodes where db_cluster_id =  $cluster_id limit 1,1;`
--echo $dst_shard_id
--let $src_shard_id = `select distinct shard_id from shard_nodes where db_cluster_id =  $cluster_id limit 0,1;`
--echo $src_shard_id


--connection cluster_mgr_http1
--http
request_type: POST
header:Content-Type:application/json
body:{
        "version":"1.0",
        "job_id":"",
        "job_type":"expand_cluster",
        "timestamp" : "1435749309",
        "user_name":"kunlun_test",
        "paras":{ 
               "cluster_id":"${cluster_id}",
               "dst_shard_id":"${dst_shard_id}",
               "src_shard_id":"${src_shard_id}",
               "table_list":["postgres.public.student"]
                 }
}
EOF

--let $job_id = `http_reap(job_id)`
--sleep 20
#--source kunlun-test/include/wait_http_request_finish.inc
--connection default
--let $expand_status = query_get_value(select status from cluster_general_job_log  where job_type = "expand_cluster" and status = "failed",status,1)
--echo $expand_status

